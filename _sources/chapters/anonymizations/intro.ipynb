{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b704387-bbbd-4e68-994c-830a4e01beaf",
   "metadata": {},
   "source": [
    "# Anonymization techniques\n",
    "\n",
    "## Motivating examples\n",
    "These examples were taken from {cite:p}`twitter-icwsm22`.\n",
    "\n",
    "### Medical data linking \n",
    "This example was copied from {cite}`sadf`.\n",
    "The National Association of Health Data Organizations (NAHDO) reported\n",
    "that 37 states in the USA have legislative mandates to collect hospital level\n",
    "data and that 17 states have started collecting ambulatory care data from\n",
    "hospitals, physicians offices, clinics, and so on. The leftmost circle in\n",
    "Figure 1 contains a subset of the fields of information, or attributes, that\n",
    "NAHDO recommends these states collect; these attributes include the\n",
    "patient’s ZIP code, birth date, gender, and ethnicity.\n",
    "In Massachusetts, the Group Insurance Commission (GIC) is responsible\n",
    "for purchasing health insurance for state employees. GIC collected patientspecific\n",
    "data with nearly one hundred attributes per encounter along the lines\n",
    "of the those shown in the leftmost circle of Figure 1 for approximately\n",
    "135,000 state employees and their families. Because the data were believed to\n",
    "be anonymous, GIC gave a copy of the data to researchers and sold a copy to\n",
    "industry.\n",
    "For twenty dollars I purchased the voter registration list for Cambridge\n",
    "Massachusetts and received the information on two diskettes. The\n",
    "rightmost circle in Figure 1 shows that these data included the name, address,\n",
    "ZIP code, birth date, and gender of each voter. This information can be linked\n",
    "using ZIP code, birth date and gender to the medical information, thereby linking diagnosis, procedures, and medications to particularly named individuals.\n",
    "\n",
    "\n",
    "<figure>\n",
    "  <img src=\"../../figs/linking-attack.png\" alt=\"Image description\">\n",
    "  <figcaption>Linking to re-identify data (from Latanya Sweeney, 2002).</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "For example, William Weld was governor of Massachusetts at that time\n",
    "and his medical records were in the GIC data. Governor Weld lived in\n",
    "Cambridge Massachusetts. According to the Cambridge Voter list, six people\n",
    "had his particular birth date; only three of them were men; and, he was the\n",
    "only one in his 5-digit ZIP code.\n",
    "\n",
    "### Web search log\n",
    "Another well-known privacy incident came from publishing web search logs. In 2006, AOL\n",
    "released three months of search logs involving 650,000 users. The main privacy protection technique\n",
    "used is replacing user ids with random numbers. This proved to be a failure. Two New\n",
    "York Times journalists, Barbaro and Tom Zeller [2006], were able to re-identify elma Arnold,\n",
    "a 62-year-old women living in Lilburn, GA, from the published search logs. Ms. Arnold’s search\n",
    "log includes her last name and location names near where she lived. The reporters were able to\n",
    "cross-reference this information with phonebook entries. After the New York Times article had\n",
    "been published, the data was immediately retracted by AOL. Later a class action lawsuit was\n",
    "filed against AOL. This scandal led to the resignation of AOL’s CTO and the dismissal of two\n",
    "employees.\n",
    "\n",
    "### Netflix\n",
    "In 2009, Netflix released a dataset containing the movie rating data from 500,000 users\n",
    "as part of a one-million dollar challenge to the data mining research community for developing\n",
    "effective algorithms for predicting users’ movie preferences based on their viewing history\n",
    "and ratings. While the data was anonymized in order to protect users’ privacy, Narayanan and\n",
    "Shmatikov [2008] showed that an adversary having some knowledge about a subscriber’s movie\n",
    "viewing experience can easily identify the subscriber’s record if present in the dataset. For example,\n",
    "Narayanan and Shmatikov [2008] showed that, from the profiles of 50 IMDB users, at least\n",
    "two of them also appear in the Netflix dataset.\n",
    "\n",
    "### Genome data leak\n",
    "Another privacy incident targeted the Genome-Wide Association Studies (GWAS). These\n",
    "studies normally compare the DNA sequences of two groups of participants: people with the\n",
    "disease (cases) and similar people without (controls). Each person’s DNA mutations (singlenucleotide\n",
    "polymorphisms, or SNPs) at indicative locations are read, and this information is then\n",
    "analyzed. Traditionally, researchers publish aggregate frequencies of SNPs for participants in the\n",
    "two groups. In 2008, Homer et al. [2008] proposed attacks that could tell with high confidence\n",
    "whether an individual is in the case group, assuming that the individual’s DNA is known. e\n",
    "attack works even if the group includes hundreds of individuals. Because of the privacy concerns\n",
    "from such attacks, a number of institutions, including the U.S. National Institute of Health\n",
    "(NIH) and the Wellcome Trust in London all decided to restrict access to data from GWAS.\n",
    "Such attacks need access to the victim’s DNA data and publicly available genomic database to\n",
    "establish the likely SNP frequencies in the general population.\n",
    "Another example of the failure of naive “data anonymization” is location-based social\n",
    "networks that provide friend discovery feature by location proximity, documented by Li et al.\n",
    "[2014b]. These social networks try to provide some privacy protection by using a number of\n",
    "location-obfuscating techniques. One technique is to show to a user only relative distances of\n",
    "other users to her, instead of their location coordinates. Another is to set a limit on the precision\n",
    "of the reported information. For example, Skout defines localization accuracy to 1 mile, i.e., users\n",
    "will be located with an accuracy no better than 1 mile. Similarly, Wechat and Momo set 100 m and 10 m as their localization accuracy limits. Yet another technique is to restrict a user’s view\n",
    "to within a certain distance of the user, or to no more than a certain number of users. Li et al.\n",
    "[2014b] demonstrated the effectiveness of attacks that use lots of fake locations to issue many\n",
    "queries and then aggregate this information to infer the exact locations of users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886d6bba-64c7-4190-83e0-1ae7389e1eb1",
   "metadata": {},
   "source": [
    "---\n",
    "**References**\n",
    "```{bibliography}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b35bc0-4ba9-46fe-8ccb-d7a79ca7f354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

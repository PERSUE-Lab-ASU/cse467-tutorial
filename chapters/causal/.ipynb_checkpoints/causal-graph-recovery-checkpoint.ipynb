{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfc0fbd6-be00-4feb-b61f-094321a08814",
   "metadata": {},
   "source": [
    "# Recovering causal graphs\n",
    "\n",
    "We have seen that we can estimate the causal effect of a variable $X$ on another variable $Y$ from observational data. For direct causal effect estimation, one common problem we encounter is the effects of confounding variables, which we can remove using techniques like covariate or propensity score matching. For example, in the diagram below, to estimate the causal effect of `risk awareness` on the use of a password manager, we would need to remove the confounding effect of `past experiences` that may affect both awareness of possible risks and decision to use a password manager. \n",
    "\n",
    "```{figure} PM-use.png\n",
    "---\n",
    "height: 400px\n",
    "name: pm-use\n",
    "---\n",
    "Example causal graph showing the variables that may affect someone's decision to (not) use a password manager.\n",
    "```\n",
    "\n",
    "But even before that, we would need to create the diagram, which represents how the data was generated. That means we will need to specify the (causal and non-causal) relationships among the variables. This step requires manual involvement and expert domain knowledge, and is time consuming. Doing this for a lot of variables (predictors) may not be feasible. Fortunately, there are algorithms that can recover this graph from data, which is the topic for this chapter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efce168-2bc5-4fb5-a304-3dc42925861b",
   "metadata": {},
   "source": [
    "## Dependency and conditional dependency\n",
    "\n",
    "If two variables are dependent---i.e., their probability distribution depends on each other, and they are associated---then there will be at least one path connecting them in the graph. The path can be directed, if the association is causal, otherwise undirected. Two variables can be dependent or independent when we condition on some other variable(s). (Remember, conditioning means setting sepecific values to the variable being conditioned on). Following we will look at different configurations of three variables, and when two of them are dependent on each other, and what happens to that dependency when we condition on the third variable.\n",
    "![figure](direct-chain.png)\n",
    "\n",
    "In the above diagram, $X_1$,$X_2$, and $X_3$ are connected forming a chain structure. Are $X_1$ and $X_3$ dependent on each other? Yes, because $X_1$ affects $X_2$, which affects $X_3$. So the effect of $X_1$ will flow to $X_3$ (indirect causal effect). We write: $X_1 \\not\\perp\\!\\!\\!\\perp X_3$. What if we condition on $X_2$? In that case, $X_1$ and $X_3$ are not dependent anymore. We say that, they are independent conditioned on $X_2$ ( we write: $X_1 \\perp\\!\\!\\!\\perp X_3  |  X_2$).\n",
    "\n",
    "What about the following diagram, which shows a fork structure among the three variable? Is $X_1 \\not\\perp\\!\\!\\!\\perp X_3$? Yes, $X_1$ and $X_3$ are dependent on each other, because $X2$ affects both of them. Doe they become independent conditioned on $X_2$? Also yes!\n",
    "![figure](fork.png)\n",
    "\n",
    "The final structure we will see is called immorality, which creates a collider structure at node $X_2$. Is $X_1 \\not\\perp\\!\\!\\!\\perp X_3$? The answer is surprisingly, no! $X_1$ and $X_3$ are independent, but they become dependent when we condition on $X_2$, the opposite of the above two cases. Thus, Is $X_1 \\not\\perp\\!\\!\\!\\perp X_3 | X_2$.\n",
    "![figure](collider.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a758f-ba70-4ee6-b34b-f82426a24666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

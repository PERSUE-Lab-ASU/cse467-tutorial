{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccdc3879-d01a-4b34-b0b0-d0a3d66212b6",
   "metadata": {},
   "source": [
    "# Data utility\n",
    "\n",
    "Data is collected and released for its usefulness. Privacy-preserving mechanisms, such as k-anonymity, removes parts of the data, and thus may lower utility. But how much utility is retained in a privacy-enhanced version of a dataset? There are two methods to measure this: general data utility metrics or usefulness metrics of something else derived from the data (e.g., the accuracy of a machine learning model trained on the dataset in question). We will look at the first category in this chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cee0cd0-926d-4741-a86b-98c9b99b5bd6",
   "metadata": {},
   "source": [
    "## Generalization or Suppression Counting\n",
    "\n",
    "One of the most intuitive measure of loss of utility is the number of privacy operations (generalization and suppression) has been performed, since each operation makes the data more generic and removes some utility. Consider the generalization steps on Race and Zip for the tuple $<Asian, 94141> \\rightarrow_{[1,1]} <person, 9414*>$. The number of operations here is 2, which can also be considered as proportional to the information that was lost. If only generalization is used, this loss is also equal to the height of the node in the tuple domain hierarchy.\n",
    "\n",
    "One proglem with this measure is that it treats information loss for all operations as equal. But generalizing Race once completely removes any information about race ($Asian\\rightarrow person$), but doing so for zip only removes some information (we can still guess the larger areas based on the remaining four digits). Even for the same attribute, (repeated) generalization operations can have different impact (compare 9414* to 941**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2654add4-b093-45f6-b12c-bb74144d7f23",
   "metadata": {},
   "source": [
    "## Average size of equivalence classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ea4c5-05f0-446b-86d1-f83432d3c9b3",
   "metadata": {},
   "source": [
    "## Loss Metric\n",
    "\n",
    "This metric was proposed by Vijay Iyengar{cite}`iyengarLossMetric` and takes account of the number of levels and values of the generalization hierarchy of an attribute. Consider the attribute `employment type`, which has the following hierarchy of values. In a dataset, the values in the leaf node are specified, and intermediate node values can be used while generalizing (e.g., `Local government employee` can be replaced by `Government employee`). \n",
    "\n",
    "```{figure} emp-tree.png\n",
    "---\n",
    "height: 400px\n",
    "name: emp-tree\n",
    "---\n",
    "Example of value hierarchy of an attribute.\n",
    "```\n",
    "If the generalized value corresponds to node `P` in the taxonomy tree `T`, and the total number of leaf nodes in `T` is $M$ and the number of leaf nodes in the subtree rooted at `P` is $M_P$, then the Loss metric, $LM = \\frac{M_P-1}{M-1}$. For the above example, $LM = \\frac{2}{7}$. The loss for a suppressed entry is the same\n",
    "as the loss when the generalized value corresponds to the root of the tree. Intuitively, this loss value is proportional to the *width* of the node `P`.\n",
    "\n",
    "Numeric attributes are generalized using ranges (e.g., replacing age of 62 with the age range [55-64]). The loss metric for such columns are $LM = \\frac{U_i-L_i}{U-L}$ where $U_i$ and $L_i$ are the upper and lower end of the new interval, $U$ and $L$ are the highest and lowest value of that column in the associated dataset.\n",
    "\n",
    "The total loss for an attribute $A$ is the average loss of $A$ for all tuples in the table. The loss metric for the whole table is just the (possibly weighted) sum of loss metrics for each attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34133b9-2055-4262-814a-4fe3ad3cc574",
   "metadata": {},
   "source": [
    "## Discernibility metric\n",
    "\n",
    "Another loss metric is called discernability metric, and defined as $DM = n * S + \\sum_{i=1}^{NEQ} {(EQ_i)}^2$ \\\n",
    "where,\\\n",
    "$n= |T|$ \\\n",
    "$S=$ number of suppressed tuples\\\n",
    "$NEQ=$ number of equivalence class\\\n",
    "$|EQ_i| =$ size of the *ith* equivalent class $EQ_i$ \n",
    "\n",
    "Thus, $DM$ assigns a penalty to each tuple based on how many other\n",
    "tuples in the database are indistinguishable from it (i.e., the sizes of equivalent classes). For a database of size $n$, $DM$ assigns a penalty of $n$ for each suppressed tuple. If a tuple is not suppressed, the penalty it receives is the total number of tuples in the equivalence class it belongs to. Intuitively, having too big equivalent classes (i.e., generalizing too much) will increase $DM$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6254025e-cf07-4b65-b7cf-7b1c2a32f22c",
   "metadata": {},
   "source": [
    "## Distortion\n",
    "\n",
    "This is an information theoretic measure, and unlike the previous ones, it takes into account the distribution of the attribute in question. This is defined as\n",
    "\n",
    "$DIST = \\frac{H(QI_{pre}) - H(QI_{post})}{\\log_2{|N|}}$\\\n",
    "where,\\\n",
    "$|N|=$ number of tuples in the anonymized table\\\n",
    "$H(D)=$ the entropy of a distribution $D$\\\n",
    "$QI_{pre}=$ the distribution of the quasi-identifiers *before* anonymization\\\n",
    "$QI_{post}=$ the distribution of the quasi-identifiers *after* anonymization\n",
    "\n",
    "Intuitively, it measures how much entropy was lost (i.e., loss in uniqueness of the QI values), normalized by the total number of tuples.\n",
    "\n",
    "For the following anonymization (`QI={Race, Gender}`), we have $QI_{pre}={{M, Black}, {M, Asian}, {F,Asian}, {M,White}, {F,White}, {F, Black}}$ and $QI_{post}={{*, Black}, {*, Asian}, {*, White}}$. So,\\\n",
    "$H(QI_{pre})=-6 *1/6*\\log_2⁡(1/6)\\approx2.585$\\\n",
    "$H(QI_{post})=-3 *1/3*\\log_2⁡(1/3)\\approx1.585$\\\n",
    "$D=\\frac{2.585-1.585}{\\log_2{6}}=\\frac{1}{\\log_2{6}}$\n",
    "\n",
    "```{figure} distortion.png\n",
    "---\n",
    "height: 250px\n",
    "name: distortion\n",
    "---\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
